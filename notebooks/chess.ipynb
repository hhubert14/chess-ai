{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyPtO9uGq5R8Vx9H+yMsvFPE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d14a672213dd4abd803d6146f27669b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_57e9a3e3e3674988b79f1950a37acaf3",
              "IPY_MODEL_d5f6945cdc644b89a2ea885ef545969f",
              "IPY_MODEL_b3d03771f9d74decb588cf8a3cab1337"
            ],
            "layout": "IPY_MODEL_6b2481a55ea043368879ffa04ba4e6c4"
          }
        },
        "57e9a3e3e3674988b79f1950a37acaf3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_848f458f7cfe472083746fa44b1646f1",
            "placeholder": "​",
            "style": "IPY_MODEL_e0b5961efbb84ae7bd04e9377360c30f",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "d5f6945cdc644b89a2ea885ef545969f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6bdd878546c451685d6ebcd432aed3f",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1fc4ef290d0a422db4de337576823e94",
            "value": 3
          }
        },
        "b3d03771f9d74decb588cf8a3cab1337": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ecface1357f84de08fa21c9755f39427",
            "placeholder": "​",
            "style": "IPY_MODEL_ea276dd6f3f348549a64b2ab2887ee62",
            "value": " 3/3 [00:00&lt;00:00,  3.10it/s]"
          }
        },
        "6b2481a55ea043368879ffa04ba4e6c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "848f458f7cfe472083746fa44b1646f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0b5961efbb84ae7bd04e9377360c30f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a6bdd878546c451685d6ebcd432aed3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fc4ef290d0a422db4de337576823e94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ecface1357f84de08fa21c9755f39427": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea276dd6f3f348549a64b2ab2887ee62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0f3836c269f947ad9bc2059ee2046a7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_508314a5533a4434a8010f19006591f4",
              "IPY_MODEL_3c3cda852ca04670ab6e89438ca1b052",
              "IPY_MODEL_1865045fc8664ed6aa58f21302f8323d"
            ],
            "layout": "IPY_MODEL_ebcc6a52a09e4a58a8dd3ef55db3828c"
          }
        },
        "508314a5533a4434a8010f19006591f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e603fafbd034e98bce8fea170a8a92f",
            "placeholder": "​",
            "style": "IPY_MODEL_64635e566cae4fee8b137cc623071a34",
            "value": ""
          }
        },
        "3c3cda852ca04670ab6e89438ca1b052": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c1316333aa84084a466b166ba26072a",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8a5c14d9ce6e4680ae5b8b4875a78600",
            "value": 1
          }
        },
        "1865045fc8664ed6aa58f21302f8323d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46fcf18c157e4963871ac9443c603786",
            "placeholder": "​",
            "style": "IPY_MODEL_a409f1c6ee5540a2a81fad97474c5fd3",
            "value": " 10640/? [36:20&lt;00:00,  4.87it/s]"
          }
        },
        "ebcc6a52a09e4a58a8dd3ef55db3828c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e603fafbd034e98bce8fea170a8a92f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64635e566cae4fee8b137cc623071a34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3c1316333aa84084a466b166ba26072a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "8a5c14d9ce6e4680ae5b8b4875a78600": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "46fcf18c157e4963871ac9443c603786": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a409f1c6ee5540a2a81fad97474c5fd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hhubert14/chess-ai/blob/main/chess.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets\n",
        "# !pip install --upgrade torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "# !pip install transformers==4.38.0\n",
        "!pip install --upgrade transformers\n",
        "!pip install --upgrade peft"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uP9YyXDKbd3r",
        "outputId": "83cb43fa-28b7-4131-9c6a-3dd20b2c1d61"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.10)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.27.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.2.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.14.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.5.1+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft) (4.47.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft) (4.67.1)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from peft) (1.2.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft) (0.4.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.25.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.27.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.0->peft) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.0->peft) (2024.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.0->peft) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.0->peft) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (0.21.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (2024.12.14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9kFFt464b0fp",
        "outputId": "6c1b1a30-1fdf-441e-ff70-eafbc60640f6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To log in, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Enter your token (input will not be visible): \n",
            "Add token as git credential? (Y/n) n\n",
            "Token is valid (permission: read).\n",
            "The token `safafa` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `safafa`\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"  # Ensures synchronous error reporting\n",
        "os.environ['TORCH_USE_CUDA_DSA'] = \"1\"    # Enables device-side assertions\n",
        "\n",
        "# !SET TORCH_USE_CUDA_DSA = 1"
      ],
      "metadata": {
        "id": "AZm9OjfcpD57"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n"
      ],
      "metadata": {
        "id": "9BkQMioAuXqD"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True"
      ],
      "metadata": {
        "id": "EfKI21hYtaIz"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85,
          "referenced_widgets": [
            "d14a672213dd4abd803d6146f27669b8",
            "57e9a3e3e3674988b79f1950a37acaf3",
            "d5f6945cdc644b89a2ea885ef545969f",
            "b3d03771f9d74decb588cf8a3cab1337",
            "6b2481a55ea043368879ffa04ba4e6c4",
            "848f458f7cfe472083746fa44b1646f1",
            "e0b5961efbb84ae7bd04e9377360c30f",
            "a6bdd878546c451685d6ebcd432aed3f",
            "1fc4ef290d0a422db4de337576823e94",
            "ecface1357f84de08fa21c9755f39427",
            "ea276dd6f3f348549a64b2ab2887ee62"
          ]
        },
        "id": "ArEAKI0Iap_L",
        "outputId": "b710150f-7807-48ff-a3fe-09f13d497983"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d14a672213dd4abd803d6146f27669b8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 1,597,440 || all params: 2,615,939,328 || trainable%: 0.0611\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM, DataCollatorWithPadding, get_scheduler\n",
        "from datasets import load_dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import AdamW\n",
        "from accelerate.test_utils.testing import get_backend\n",
        "from tqdm.auto import tqdm\n",
        "from peft import LoftQConfig, LoraConfig, get_peft_model\n",
        "from peft import get_peft_model, LoraConfig, TaskType, prepare_model_for_kbit_training\n",
        "\n",
        "import torch\n",
        "\n",
        "# TODO add validation set\n",
        "\n",
        "# Adjustable variables\n",
        "model_name = \"google/gemma-2-2b\"\n",
        "batch_size = 4\n",
        "train_dataset_path = \"/content/train_dataset.csv\"\n",
        "test_dataset_path = \"/content/test_dataset.csv\"\n",
        "num_epochs = 5\n",
        "learning_rate = 5e-5\n",
        "model_dir = f\"{model_name}_saved\"\n",
        "\n",
        "# \"google/flan-t5-base\"\n",
        "\n",
        "# model_config = {\"rope_scaling\": {\"type\": \"linear\", \"factor\": 8.0}}\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "# model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "# model = AutoModelForCausalLM.from_pretrained(model_name, config=model_config)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "# model.gradient_checkpointing_enable()\n",
        "# model.half()\n",
        "\n",
        "peft_config = LoraConfig(inference_mode=False, r=8, lora_alpha=32, lora_dropout=0.1, peft_type=TaskType.CAUSAL_LM)\n",
        "# loftq_config = LoftQConfig(loftq_bits=4, ...)           # set 4bit quantization\n",
        "# lora_config = LoraConfig(..., init_lora_weights=\"loftq\", loftq_config=loftq_config)\n",
        "model = get_peft_model(model, peft_config)\n",
        "print(model.print_trainable_parameters())\n",
        "\n",
        "\n",
        "# Load datasets in streaming mode\n",
        "train_dataset = load_dataset(\"csv\", data_files={\"full\": train_dataset_path}, streaming=True)[\"full\"]\n",
        "eval_dataset = load_dataset(\"csv\", data_files={\"full\": test_dataset_path}, streaming=True)[\"full\"]\n",
        "\n",
        "# Tokenize dynamically using a collate function\n",
        "tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "tokenizer.pad_token_id = tokenizer.pad_token_id  # Ensure tokenizer uses the same pad token for labels\n",
        "tokenizer.label_pad_token_id = tokenizer.pad_token_id  # Set"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_batch(batch):\n",
        "    inputs_text = [example[\"inputs\"] for example in batch]\n",
        "    labels_text = [example[\"label\"] for example in batch]\n",
        "\n",
        "    # print(f\"Number of inputs: {len(inputs_text)}, Number of labels: {len(labels_text)}\")\n",
        "    # assert len(inputs_text) == len(labels_text), \"Mismatch in input and label sizes\"\n",
        "\n",
        "\n",
        "    # combined_text = inputs_text + labels_text\n",
        "    # tokenized_batch = tokenizer(\n",
        "    #     combined_text,\n",
        "    #     truncation=True,\n",
        "    #     padding=True,\n",
        "    #     # max_length=512,\n",
        "    #     return_tensors=\"pt\"\n",
        "    #     )\n",
        "    # print(f\"tkid: {tokenized_batch}\")\n",
        "    # print(f\"tkid: {tokenized_batch['input_ids']}\")\n",
        "\n",
        "    # inputs = tokenizer(inputs_text, truncation=True, padding=True, max_length=512, return_tensors=\"pt\")\n",
        "    # labels = tokenizer(labels_text, truncation=True, padding=True, max_length=512, return_tensors=\"pt\")\n",
        "    inputs = tokenizer(\n",
        "        inputs_text,\n",
        "        truncation=\"only_first\",\n",
        "        padding=\"max_length\",\n",
        "        max_length=256,\n",
        "        return_tensors=\"pt\",\n",
        "        add_special_tokens=True,\n",
        "        )\n",
        "    labels = tokenizer(\n",
        "        labels_text,\n",
        "        truncation=\"only_first\",\n",
        "        padding=\"max_length\",\n",
        "        max_length=256,\n",
        "        return_tensors=\"pt\",\n",
        "        add_special_tokens=True,\n",
        "        )\n",
        "\n",
        "    # Replace pad token in labels with -100 to ignore during loss computation\n",
        "    # labels[\"input_ids\"][labels[\"input_ids\"] == tokenizer.pad_token_id] = -100\n",
        "    inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "\n",
        "    # print(f\"inputs: {inputs}\")\n",
        "    # print(f\"labels: {labels}\")\n",
        "    # print(f\"Inputs shape: {inputs['input_ids'].shape}\")\n",
        "    # print(f\"Labels shape: {labels['input_ids'].shape}\")\n",
        "    return inputs"
      ],
      "metadata": {
        "id": "Z3gq-FCXZ2QK"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DataLoaders\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, collate_fn=tokenize_batch)\n",
        "eval_dataloader = DataLoader(eval_dataset, batch_size=batch_size, collate_fn=tokenize_batch)"
      ],
      "metadata": {
        "id": "trxiSeDXZr5v"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Scheduler (num_training_steps calculated dynamically)\n",
        "lr_scheduler = get_scheduler(\n",
        "    name=\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=1  # Placeholder\n",
        ")\n",
        "\n",
        "# Device setup\n",
        "device, _, _ = get_backend()\n",
        "print(f\"Using device: {device}\")\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3lM5kHYZtV_",
        "outputId": "9a79cbb5-d08e-4254-fcca-6f2fe3f24245"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PeftModel(\n",
              "  (base_model): LoraModel(\n",
              "    (model): Gemma2ForCausalLM(\n",
              "      (model): Gemma2Model(\n",
              "        (embed_tokens): Embedding(256001, 2304, padding_idx=0)\n",
              "        (layers): ModuleList(\n",
              "          (0-25): 26 x Gemma2DecoderLayer(\n",
              "            (self_attn): Gemma2Attention(\n",
              "              (q_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=2304, out_features=2048, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=2304, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=2048, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (k_proj): Linear(in_features=2304, out_features=1024, bias=False)\n",
              "              (v_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=2304, out_features=1024, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=2304, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=1024, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (o_proj): Linear(in_features=2048, out_features=2304, bias=False)\n",
              "              (rotary_emb): Gemma2RotaryEmbedding()\n",
              "            )\n",
              "            (mlp): Gemma2MLP(\n",
              "              (gate_proj): Linear(in_features=2304, out_features=9216, bias=False)\n",
              "              (up_proj): Linear(in_features=2304, out_features=9216, bias=False)\n",
              "              (down_proj): Linear(in_features=9216, out_features=2304, bias=False)\n",
              "              (act_fn): PytorchGELUTanh()\n",
              "            )\n",
              "            (input_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
              "            (post_attention_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
              "            (pre_feedforward_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
              "            (post_feedforward_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
              "          )\n",
              "        )\n",
              "        (norm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
              "      )\n",
              "      (lm_head): Linear(in_features=2304, out_features=256001, bias=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train\n",
        "progress_bar = tqdm(total=None)  # Dynamic progress bar\n",
        "model.train()\n",
        "step_count = 0  # Manually count steps\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"Epoch: {epoch + 1}/{num_epochs}\")\n",
        "    for batch in train_dataloader:\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "\n",
        "        outputs = model(**batch)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "        progress_bar.update(1)\n",
        "\n",
        "        step_count += 1  # Increment step count\n",
        "\n",
        "progress_bar.close()\n",
        "\n",
        "# Update lr_scheduler with actual training steps\n",
        "lr_scheduler = get_scheduler(\n",
        "    name=\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=step_count\n",
        ")\n",
        "\n",
        "# Evaluate\n",
        "model.eval()\n",
        "predictions_text = []\n",
        "for batch in eval_dataloader:\n",
        "    print(\"Input shape:\", batch[\"input_ids\"].shape)\n",
        "    print(\"Labels shape:\", batch[\"labels\"].shape)\n",
        "    batch = {k: v.to(device) for k, v in batch.items()}\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**batch)\n",
        "\n",
        "    # Use model.generate for predicti   ons\n",
        "    generated_ids = model.generate(input_ids=batch[\"input_ids\"], max_length=512)\n",
        "    # generated_ids = model.generate(input_ids=batch[\"input_ids\"])\n",
        "\n",
        "    decoded_preds = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
        "    predictions_text.extend(decoded_preds)\n",
        "\n",
        "print(len(predictions_text))\n",
        "print(predictions_text)\n",
        "\n",
        "model.save_pretrained(model_dir)  # Save model\n",
        "tokenizer.save_pretrained(model_dir)  # Save tokenizer\n",
        "\n",
        "print(f\"Model and tokenizer saved to {model_dir}\")\n"
      ],
      "metadata": {
        "id": "_S33FodrbFze",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 730,
          "referenced_widgets": [
            "0f3836c269f947ad9bc2059ee2046a7d",
            "508314a5533a4434a8010f19006591f4",
            "3c3cda852ca04670ab6e89438ca1b052",
            "1865045fc8664ed6aa58f21302f8323d",
            "ebcc6a52a09e4a58a8dd3ef55db3828c",
            "1e603fafbd034e98bce8fea170a8a92f",
            "64635e566cae4fee8b137cc623071a34",
            "3c1316333aa84084a466b166ba26072a",
            "8a5c14d9ce6e4680ae5b8b4875a78600",
            "46fcf18c157e4963871ac9443c603786",
            "a409f1c6ee5540a2a81fad97474c5fd3"
          ]
        },
        "outputId": "25205d54-b841-40b9-c6dd-3d648164e041"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0f3836c269f947ad9bc2059ee2046a7d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/10\n",
            "Epoch: 2/10\n",
            "Epoch: 3/10\n",
            "Epoch: 4/10\n",
            "Epoch: 5/10\n",
            "Epoch: 6/10\n",
            "Epoch: 7/10\n",
            "Epoch: 8/10\n",
            "Epoch: 9/10\n",
            "Epoch: 10/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The 'batch_size' argument of HybridCache is deprecated and will be removed in v4.49. Use the more precisely named 'max_batch_size' argument instead.\n",
            "The 'batch_size' attribute of HybridCache is deprecated and will be removed in v4.49. Use the more precisely named 'self.max_batch_size' attribute instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([1, 256])\n",
            "Labels shape: torch.Size([1, 256])\n",
            "Input shape: torch.Size([1, 256])\n",
            "Labels shape: torch.Size([1, 256])\n",
            "Input shape: torch.Size([1, 256])\n",
            "Labels shape: torch.Size([1, 256])\n",
            "Input shape: torch.Size([1, 256])\n",
            "Labels shape: torch.Size([1, 256])\n",
            "Input shape: torch.Size([1, 256])\n",
            "Labels shape: torch.Size([1, 256])\n",
            "Input shape: torch.Size([1, 256])\n",
            "Labels shape: torch.Size([1, 256])\n",
            "Input shape: torch.Size([1, 256])\n",
            "Labels shape: torch.Size([1, 256])\n",
            "Input shape: torch.Size([1, 256])\n",
            "Labels shape: torch.Size([1, 256])\n",
            "Input shape: torch.Size([1, 256])\n",
            "Labels shape: torch.Size([1, 256])\n",
            "Input shape: torch.Size([1, 256])\n",
            "Labels shape: torch.Size([1, 256])\n",
            "10\n",
            "[\"It is White's turn to move. The board position is:\\nr . b q k b n r\\np p . . p p p p\\n. . n p . . . .\\n. B p . . . . .\\n. . . . P . . .\\n. . . . . N . .\\nP P P P . P P P\\nR N B Q K . . R\\nThe best move is e1g1. Explain why e1g1 is the best move.\\nThe best move is e1g1. Explain why e1g1 is the best move.\\nThe best move is e1g1. Explain why e1g1 is the best move.\\nThe best move is e1g1. Explain why e1g1 is the best move.\\nThe best move is e1g1. Explain why e1g1 is the best move.\\nThe best move is e1g1. Explain why e1g1 is the best move.\\nThe best move is e1g1. Explain why e1g1 is the best move.\\nThe best move is e1g1. Explain why e1g1 is the best move.\\nThe best move is e1g1. Explain why e1g1 is the best move.\\nThe best move is e1g1. Explain why e1g1 is the best move.\\nThe best move is e1g1. Explain why e1g1 is the best move.\\nThe best move is e1g1. Explain why e1g1 is the best move.\\nThe best move is e1g1. Explain why e1g1 is the best move.\\nThe best move\", \"It is Black's turn to move. The board position is:\\n. . b r . r k .\\n. . . . R N b p\\nq . . . . . p B\\n. p p P . . . .\\n. . . . . . . .\\n. . . . . Q . P\\nP P . . . P P .\\nR . . . . . K .\\nThe best move is d8d7. Explain why d8d7 is the best move.\\n(Hint: You may want to use the notation of the previous problem.)\", \"It is Black's turn to move. The board position is:\\nr n . q . r k .\\np b p . b p p p\\n. p . . p n . .\\n. . . . . . B .\\n. . Q P . . . .\\nP . N . P N . .\\n. P . . B P P P\\nR . . . K . . R\\nThe best move is b8d7. Explain why b8d7 is the best move.\\nThe best move is b8d7. Explain why b8d7 is the best move.\\nThe best move is b8d7. Explain why b8d7 is the best move.\\nThe best move is b8d7. Explain why b8d7 is the best move.\\nThe best move is b8d7. Explain why b8d7 is the best move.\\nThe best move is b8d7. Explain why b8d7 is the best move.\\nThe best move is b8d7. Explain why b8d7 is the best move.\\nThe best move is b8d7. Explain why b8d7 is the best move.\\nThe best move is b8d7. Explain why b8d7 is the best move.\\nThe best move is b8d7. Explain why b8d7 is the best move.\\nThe best move is b8d7. Explain why b8d7 is the best move.\\nThe best move is b8d7. Explain why b8d7 is the best move.\\nThe best move is b8d7. Explain why b8d7 is the best move.\\nThe best move\", \"It is Black's turn to move. The board position is:\\n. . . . q . k .\\n. . . . . . . p\\np p . Q b P p .\\n. . . . . . . .\\n. . . . . . . .\\n. . . . . . . P\\n. P . . . . P .\\n. . . . . R . K\\nThe best move is b6b5. Explain why b6b5 is the best move.\\n(Hint: You may want to use the notation of the previous problem.)\", \"It is White's turn to move. The board position is:\\nr . . q r . k .\\np b . . . p b p\\nn p . n . . p .\\n. . p P . . . .\\n. . . . . B . .\\n. P N . . . P P\\nP . . Q N P B .\\n. . . R . R K .\\nThe best move is h3h4. Explain why h3h4 is the best move.\\nWhite's move is h3h4.\\nBlack's move is h4h5.\\nWhite's move is h5h6.\\nBlack's move is h6h7.\\nWhite's move is h7h8.\\nBlack's move is h8h9.\\nWhite's move is h9h10.\\nBlack's move is h10h11.\\nWhite's move is h11h12.\\nBlack's move is h12h13.\\nWhite's move is h13h14.\\nBlack's move is h14h15.\\nWhite's move is h15h16.\\nBlack's move is h16h17.\\nWhite's move is h17h18.\\nBlack's move is h18h19.\\nWhite's move is h19h20.\\nBlack's move is h20h21.\\nWhite's move is h21h22.\\nBlack's move is h22h23.\\nWhite's move is h23\", \"It is White's turn to move. The board position is:\\nr . . . k b n r\\np p . b q p p p\\n. . n . . . . .\\n. B . Q P . . .\\n. . . . p . . .\\n. . N . . . . .\\nP P . . . P P P\\nR . B . K . N R\\nThe best move is g1e2. Explain why g1e2 is the best move.\\nWhite's move is g1e2.\\nBlack's move is g2e3.\\nWhite's move is g3e4.\\nBlack's move is g4e5.\\nWhite's move is g5e6.\\nBlack's move is g6e7.\\nWhite's move is g7e8.\\nBlack's move is g8e9.\\nWhite's move is g9e10.\\nBlack's move is g10e11.\\nWhite's move is g11e12.\\nBlack's move is g12e13.\\nWhite's move is g13e14.\\nBlack's move is g14e15.\\nWhite's move is g15e16.\\nBlack's move is g16e17.\\nWhite's move is g17e18.\\nBlack's move is g18e19.\\nWhite's move is g19e20.\\nBlack's move is g20e21.\\nWhite's move is g21e22.\", \"It is Black's turn to move. The board position is:\\nr . . . . r k .\\n. p p . . p p p\\np . . . . . . .\\n. . . N p . . .\\n. . P . P . n .\\n. . . . . . . .\\nP P . . . P P P\\nR . . . R . K .\\nThe best move is g4f6. Explain why g4f6 is the best move.\\n(Hint: You may want to use the notation of the previous problem.)\\n\\nShow more\\nStep 1\\n1 of 2\\n\\nWe have to find the best move for Black.\\n\\nWe have to find the best move for Black.\\n\\nWe have to find the best move for Black.\\n\\nWe have to find the best move for Black.\\n\\nWe have to find the best move for Black.\\n\\nWe have to find the best move for Black.\\n\\nWe have to find the best move for Black.\\n\\nWe have to find the best move for Black.\\n\\nWe have to find the best move for Black.\\n\\nWe have to find the best move for Black.\\n\\nWe have to find the best move for Black.\\n\\nWe have to find the best move for Black.\\n\\nWe have to find the best move for Black.\\n\\nWe have to find the best move for Black.\\n\\nWe have to find the best move for Black.\\n\\nWe have to find the best move for Black.\\n\\nWe have to find the best move for Black.\\n\\nWe have to find the best move for Black.\\n\\nWe have to find the best move for Black.\\n\\nWe have to find the best move for Black.\\n\\nWe have to find the best move\", \"It is White's turn to move. The board position is:\\nr . b q k b . r\\np p p . . p p p\\n. . n . . . . .\\n. . . p . . . .\\n. . . P n . . .\\n. . . B . N . .\\nP P P . . P P P\\nR N B Q K . . R\\nThe best move is e1g1. Explain why e1g1 is the best move.\\nThe best move is e1g1. Explain why e1g1 is the best move.\\nThe best move is e1g1. Explain why e1g1 is the best move.\\nThe best move is e1g1. Explain why e1g1 is the best move.\\nThe best move is e1g1. Explain why e1g1 is the best move.\\nThe best move is e1g1. Explain why e1g1 is the best move.\\nThe best move is e1g1. Explain why e1g1 is the best move.\\nThe best move is e1g1. Explain why e1g1 is the best move.\\nThe best move is e1g1. Explain why e1g1 is the best move.\\nThe best move is e1g1. Explain why e1g1 is the best move.\\nThe best move is e1g1. Explain why e1g1 is the best move.\\nThe best move is e1g1. Explain why e1g1 is the best move.\\nThe best move is e1g1. Explain why e1g1 is the best move.\\nThe best move\", \"It is Black's turn to move. The board position is:\\nr . b . k b n r\\n. . q p . p p p\\np . N . p . . .\\n. p . . . . . .\\n. . . . P . . .\\n. . N B B . . .\\nP P P . . P P P\\nR . . Q K . . R\\nThe best move is c7c6. Explain why c7c6 is the best move.\\nThe best move is c7c6. Explain why c7c6 is the best move.\\nThe best move is c7c6. Explain why c7c6 is the best move.\\nThe best move is c7c6. Explain why c7c6 is the best move.\\nThe best move is c7c6. Explain why c7c6 is the best move.\\nThe best move is c7c6. Explain why c7c6 is the best move.\\nThe best move is c7c6. Explain why c7c6 is the best move.\\nThe best move is c7c6. Explain why c7c6 is the best move.\\nThe best move is c7c6. Explain why c7c6 is the best move.\\nThe best move is c7c6. Explain why c7c6 is the best move.\\nThe best move is c7c6. Explain why c7c6 is the best move.\\nThe best move is c7c6. Explain why c7c6 is the best move.\\nThe best move is c7c6. Explain why c7c6 is the best move.\\nThe best move\", \"It is White's turn to move. The board position is:\\n. . . . . . . .\\n. . . . . p k p\\nR . N . . . . .\\n. . . B p . . .\\n. . P . P p b .\\n. . K . b . . .\\n. P . . . . . .\\n. . . r . . . .\\nThe best move is c4c5. Explain why c4c5 is the best move.\\nWhite's move is c4c5. Explain why c4c5 is the best move.\\nWhite's move is c4c5. Explain why c4c5 is the best move.\\nWhite's move is c4c5. Explain why c4c5 is the best move.\\nWhite's move is c4c5. Explain why c4c5 is the best move.\\nWhite's move is c4c5. Explain why c4c5 is the best move.\\nWhite's move is c4c5. Explain why c4c5 is the best move.\\nWhite's move is c4c5. Explain why c4c5 is the best move.\\nWhite's move is c4c5. Explain why c4c5 is the best move.\\nWhite's move is c4c5. Explain why c4c5 is the best move.\\nWhite's move is c4c5. Explain why c4c5 is the best move.\\nWhite's move is c4c5. Explain why c4c5 is the best move.\\nWhite's move is c4c5. Explain why c\"]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:260: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model and tokenizer saved to google/gemma-2-2b_saved\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7OlULSEQX5Nw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}